{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1\n",
    "#### David Grubman | DS-DC-18 | drgrubman@gmail.com\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "In this first project you will create a framework to scope out data science projects. This framework will provide you with a guide to develop a well-articulated problem statement and analysis plan that will be robust and reproducible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and evaluate the following problem statement: \n",
    "Determine which free-tier customers will covert to paying customers, using demographic data collected at signup (age, gender, location, and profession) and customer useage data (days since last log in, and activity score 1 = active user, 0= inactive user) based on Hooli data from Jan-Apr 2015. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. What is the outcome?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *Answer:*\n",
    "*The outcome is an indicator that describes if a \"free-tier\" customer will convert to a paying customer.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. What are the predictors/covariates? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Answer*: \n",
    "\n",
    "*The predictors/coviarties are age, gender, location, profesion, days since last log-in, and activity score. This data is collected from their sign-up information and Hooli.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. What timeframe is this data relevent for?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer: \n",
    "*The timeframe is relevant from January to April of 2015.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. What is the hypothesis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer: \n",
    "*Demographic and customer usage data will allow for a prediction to determine if a free-tier customer will convert to a paying customer.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get started with our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Create a data dictionary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer: \n",
    "\n",
    "Variable | Description | Type of Variable | Data Type notes |\n",
    ":---:| :---:| :---: | :---:\n",
    "Admit | 0 = Not Admited 1 = Admitted  | categorical | boolean\n",
    "GRE | GRE Score   | continuous | integer out of 800\n",
    "GPA | Undergrad GPA | continuous | int 0-4, 2 decimals\n",
    "Prestige | Rank of Alma Mater  | categorical | 4 = highest, 0 = lowest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. What is the outcome?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "*The outcome is an predictive model that will test if Admissions can be modeled based on GRE, GPA, and Prestige of Alma Mater.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. What are the predictors/covariates? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "*The predictors/coviarates are GRE, GPA, and Presitige of Alma Mater.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. What timeframe is this data relevent for?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "*Based on the posting data of the data, we can assume it was from the 2012-2013 academic year.*\n",
    "\n",
    "[The data is posted here.](http://blog.yhat.com/posts/logistic-regression-and-python.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. What is the hypothesis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "*GRE Score, GPA, and Prestige will allow us to create a prdictive model that determines admission into UCLA graduate school.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Problem Statement*\n",
    "*Using admissions data from UCLA from a single admissions year, determine the how likely a student is admitted to UCLA graduate school by using GRE score, GPA from previous alma mater, and prestige ranking of their undergraduate university.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Analysis Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the lab from a class as a guide, create an exploratory analysis plan. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. What are the goals of the exploratory analysis? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Answer: \n",
    "*The goals of the explarotary analysis is to gain insight into the data without running any statistical tests. This includes identifying outliers, determining the distribution of the data, identifying colinear variables, finding confidence interval margins, and understanding the data's underlying structure. *\n",
    "\n",
    "*For this dataset, basically we just want a handle on the data before the real tests are applied.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2a. What are the assumptions of the distribution of data? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "*We can assume the data is normally distributed.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2b. How will determine the distribution of your data? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Answer: \n",
    "\n",
    "*To determine the distribution we will test normality with the  Kolmogorov-Smirnov test.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3a. How might outliers impact your analysis? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Answer: \n",
    "*Outliers can have a perverse impact on the mean, standard deviation, and variance of the data, and to a lesser extent the median. For instance, a GRE score of < 100 would be cause an anomoly in the results.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3b. How will you test for outliers? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "*To Test for outliers we will find which data points are outside of 3 standard deviations of a column.* \n",
    "\n",
    "\n",
    "*Outliers can be dropped using pandas. This will drop all outliers in the GRE columns:*\n",
    "\n",
    "df[((df.GRE - df.GRE.mean()) / df.GRE.std()).abs() < 3]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4a. What is colinearity? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Answer:\n",
    "*Colinearity is a linear association between two explanatory variables. For instance if there was a perfect relationship GPA and GRE it would be difficult to produce an associative model with the data.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4b. How will you test for colinearity? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer: \n",
    "*To test for colinearity we can run pair-wise correletion of columns in pandas. A heat map will show the relationship between each variable. (dataframe.corr() in pandas)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. What is your exploratory analysis plan?\n",
    "Using the above information, write an exploratory analysis plan that would allow you or a colleague to reproduce your analysis 1 year from now. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer: \n",
    "\n",
    "#### Exploratory Analysis Plan\n",
    "\n",
    "1. Research data sources. Identify source and use of the data, as well as the time series of the data. \n",
    "\n",
    "2. Develop a data dictionary for each column of data. Determine which variables are categorical, which are continuous.\n",
    "\n",
    "3. Test for missing data / NA's / Non-integer numbers. \n",
    "    *pandas functions = dropna(), find and replace for non-integer values.*\n",
    "    \n",
    "4. Do a basic describe for each data series and create histograms for each data series. Give yourself a basic idea of the data\n",
    "    *pandas describe() plt.hist()*\n",
    "    \n",
    "5. Determine and test assumptions of normality for the the data.\n",
    "    *1-sample KS-test for each of the continuous variables. in python scipyimport kstest*\n",
    "    \n",
    "6. Determine outliers\n",
    "    *Use an outlier test (mark or drop data ove 3 STD's) in pandas on each of the variable columns - Admit, GRE, GPA, and Prestige.*\n",
    "    \n",
    "7. Test for colinearity and create a 'heatmap'\n",
    "     *pandas dataframe.corr(), sns.heatmap()*\n",
    "     \n",
    "8. Think about if it all makes sense! Return your test results and think about them in context of the data source, and data dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Questions:\n",
    "1. Outline your analysis method for predicting your outcome\n",
    "2. Write an alternative problem statement for your dataset\n",
    "3. Articulate the assumptions and risks of the alternative model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It's bonus time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit    gre   gpa  prestige\n",
       "0      0  380.0  3.61       3.0\n",
       "1      1  660.0  3.67       3.0\n",
       "2      1  800.0  4.00       1.0\n",
       "3      1  640.0  3.19       4.0"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1. Analysis plan (light..)\n",
    "#-load, scrub, describe data set\n",
    "#-determine your predictors/covariates, independent/dependent variables\n",
    "#-dummy variables for categorical data\n",
    "#-study the correlation coefficients\n",
    "#-see which type of regression is needed! logit regression\n",
    "#-run said regression and find results\n",
    "\n",
    "\n",
    "\n",
    "#Our analysis method will be a linear logistic regression as outlined by y-hat. Let's do it!\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "#WATCH OUT THIS DATA MAY HAVE MOVED!!\n",
    "df = pd.read_csv('../../project-1/assets/admissions.csv')\n",
    "df.head(4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit    gre   gpa  prestige\n",
       "0      0  380.0  3.61       3.0\n",
       "1      1  660.0  3.67       3.0\n",
       "2      1  800.0  4.00       1.0"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop some null values\n",
    "import numpy as np\n",
    "df = df.dropna() #a ha some null values\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>397.000000</td>\n",
       "      <td>397.000000</td>\n",
       "      <td>397.000000</td>\n",
       "      <td>397.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.317380</td>\n",
       "      <td>587.858942</td>\n",
       "      <td>3.392242</td>\n",
       "      <td>2.488665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.466044</td>\n",
       "      <td>115.717787</td>\n",
       "      <td>0.380208</td>\n",
       "      <td>0.947083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>520.000000</td>\n",
       "      <td>3.130000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>580.000000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>660.000000</td>\n",
       "      <td>3.670000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            admit         gre         gpa    prestige\n",
       "count  397.000000  397.000000  397.000000  397.000000\n",
       "mean     0.317380  587.858942    3.392242    2.488665\n",
       "std      0.466044  115.717787    0.380208    0.947083\n",
       "min      0.000000  220.000000    2.260000    1.000000\n",
       "25%      0.000000  520.000000    3.130000    2.000000\n",
       "50%      0.000000  580.000000    3.400000    2.000000\n",
       "75%      1.000000  660.000000    3.670000    3.000000\n",
       "max      1.000000  800.000000    4.000000    4.000000"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#simple descrptions\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>admit</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.181202</td>\n",
       "      <td>0.174116</td>\n",
       "      <td>-0.243563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gre</th>\n",
       "      <td>0.181202</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.382408</td>\n",
       "      <td>-0.124533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpa</th>\n",
       "      <td>0.174116</td>\n",
       "      <td>0.382408</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.060976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prestige</th>\n",
       "      <td>-0.243563</td>\n",
       "      <td>-0.124533</td>\n",
       "      <td>-0.060976</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             admit       gre       gpa  prestige\n",
       "admit     1.000000  0.181202  0.174116 -0.243563\n",
       "gre       0.181202  1.000000  0.382408 -0.124533\n",
       "gpa       0.174116  0.382408  1.000000 -0.060976\n",
       "prestige -0.243563 -0.124533 -0.060976  1.000000"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test for correlation\n",
    "df.corr() #no problems here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige_2.0</th>\n",
       "      <th>prestige_3.0</th>\n",
       "      <th>prestige_4.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>3.61</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit    gre   gpa  prestige_2.0  prestige_3.0  prestige_4.0\n",
       "0      0  380.0  3.61             0             1             0\n",
       "1      1  660.0  3.67             0             1             0\n",
       "2      1  800.0  4.00             0             0             0\n",
       "3      1  640.0  3.19             0             0             1\n",
       "4      0  520.0  2.93             0             0             1"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get dummies, keep certain fields\n",
    "ummies = pd.get_dummies(df['prestige'], prefix='prestige')\n",
    "cols_to_keep = ['admit', 'gre', 'gpa']\n",
    "data = df[cols_to_keep].join(dummies.ix[:, 'prestige_2':])\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.573854\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                  admit   No. Observations:                  397\n",
      "Model:                          Logit   Df Residuals:                      391\n",
      "Method:                           MLE   Df Model:                            5\n",
      "Date:                Tue, 14 Mar 2017   Pseudo R-squ.:                 0.08166\n",
      "Time:                        11:32:01   Log-Likelihood:                -227.82\n",
      "converged:                       True   LL-Null:                       -248.08\n",
      "                                        LLR p-value:                 1.176e-07\n",
      "================================================================================\n",
      "                   coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
      "--------------------------------------------------------------------------------\n",
      "gre              0.0022      0.001      2.028      0.043      7.44e-05     0.004\n",
      "gpa              0.7793      0.333      2.344      0.019         0.128     1.431\n",
      "prestige_2.0    -0.6801      0.317     -2.146      0.032        -1.301    -0.059\n",
      "prestige_3.0    -1.3387      0.345     -3.882      0.000        -2.015    -0.663\n",
      "prestige_4.0    -1.5534      0.417     -3.721      0.000        -2.372    -0.735\n",
      "intercept       -3.8769      1.142     -3.393      0.001        -6.116    -1.638\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "#built an intercept, reun a logit regression. i'm not sure why we do an intercept in this case....\n",
    "data['intercept'] = 1.0\n",
    "logit = sm.Logit(data['admit'], data[['gre', 'gpa','prestige_2.0', 'prestige_3.0', 'prestige_4.0','intercept']])\n",
    "result = logit.fit()\n",
    "print result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     0         1\n",
      "gre           0.000074  0.004362\n",
      "gpa           0.127619  1.431056\n",
      "prestige_2.0 -1.301337 -0.058936\n",
      "prestige_3.0 -2.014579 -0.662776\n",
      "prestige_4.0 -2.371624 -0.735197\n",
      "intercept    -6.116077 -1.637631\n"
     ]
    }
   ],
   "source": [
    "#for fun, confidence intervals\n",
    "print result.conf_int()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 2. Write an alternative problem statement for your dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Is there a relationship between GPA and GRE score? In other words is classwork and test scores relevant?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Articulate the assumptions and risks of the alternative model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer\n",
    "*The assumptions is that there is a relationship between these variables, and that they are normally distributed. The risks is the specific nature of this dataset. For instance, you already know these students have some capacity to be good students, by virtue of the fact that they are applying to graduate school. There is also risks in that the sample size is too small and that a certain percentage of them got admitted, therefore skewing the data.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
